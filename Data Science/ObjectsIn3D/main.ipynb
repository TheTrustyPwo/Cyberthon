{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Objects In 3D**\n",
    "\n",
    "**Problem Statement**\n",
    "\n",
    "APOCALYPSE, the nefarious organization bent on global domination, is on the cusp of unleashing their most devastating weapon yet. But there's hope. Deep within these images lie the key to stopping them.\n",
    "\n",
    "At the heart of the image is a cube, seemingly simple yet hiding a complex secret. Its position and orientation hold the power to unlock the secrets of APOCALYPSE's deadliest weapon. But time is running out, and we need your help to solve the puzzle.\n",
    "\n",
    "Attached Files\n",
    "[OutofPerspective.tar.xz](https://api.t.cyberthon24.ctf.sg/file?id=clu5ovpwl0aws0806bhyjkhii&name=OutofPerspective.tar.xz)"
   ],
   "id": "8b014a16ff934392"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Solution**\n",
    "\n",
    "We are going to use ResNet152 to get the maximum possible results\n",
    "\n",
    "The code below are to be used for colab"
   ],
   "id": "c7572694acae3b5f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "You need to put OutofPerspective.tar.xz into a folder <br>\n",
    "Mount Google Drive"
   ],
   "id": "3b9b41c664835adb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "id": "1f7c844a4139810c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!tar -xf /content/drive/MyDrive/Cyberthon/OutofPerspective.tar.xz"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Import necessary libraries"
   ],
   "id": "36b8c7f3bda1255b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "import torch.nn as nn\n",
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import models\n",
    "from PIL import Image"
   ],
   "id": "af70472218cfae9d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Creates the CustomDataset for the training data"
   ],
   "id": "88e8ebf7c2e3d4e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.df.iloc[idx, 0]\n",
    "        img_path = f\"{self.root_dir}/{img_name}\"\n",
    "        image = Image.open(img_path)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        posx = self.df.iloc[idx, 1]\n",
    "        posy = self.df.iloc[idx, 2]\n",
    "        rotx = self.df.iloc[idx, 3]\n",
    "        roty = self.df.iloc[idx, 4]\n",
    "\n",
    "        labels = torch.tensor([posx, posy, rotx, roty], dtype=torch.float32)\n",
    "\n",
    "        return image, labels"
   ],
   "id": "8dc4b75a23a46c32"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Intialise the dataset with training data <br>\n",
    "The transform is required to change the images into 3 channels instead of 4"
   ],
   "id": "cbd8b15a45af0d8d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: x[:3, :, :]),\n",
    "])\n",
    "\n",
    "dataset = CustomDataset(csv_file='package/train.csv', root_dir='package/renders', transform=transform)\n",
    "cube_loader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ],
   "id": "692b24a0727cee4b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Print out the first image in dataset"
   ],
   "id": "195fc69674f55cac"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "image = TF.to_pil_image(dataset[0][0].cpu())\n",
    "image"
   ],
   "id": "e910c64b3b38a7c9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Create the ResNet152 and fine tune it for our needs <br>\n",
    "We have 4 outputs which are posx, posy, rotx, roty so we set the final output to be 4"
   ],
   "id": "23ae63287b835501"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model = models.resnet152(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 4)"
   ],
   "id": "987ba08be9928a40"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We use HuberLoss as our loss function <br>\n",
    "We also use a learning rate scheduler to increase training efficiency"
   ],
   "id": "e8a82cf6e9d2443d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model = model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "loss_func = nn.HuberLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)"
   ],
   "id": "b6f6a710275e9436"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Time to train the model with our dataset"
   ],
   "id": "bff15fec427ff641"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "EPOCHS = 30\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    epoch_losses = []\n",
    "    for x, y in cube_loader:\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(x.to(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "        loss = loss_func(pred, y.to(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "        epoch_losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    epoch_loss = np.mean(epoch_losses)\n",
    "    print(f\"[{epoch+1}th Epoch] Training Loss: {epoch_loss}\")\n",
    "    scheduler.step()"
   ],
   "id": "103df5ca0686fc34"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Now load test.csv, get all the images and plug it into the model <br>\n",
    "Lastly, write outputs back to test.csv"
   ],
   "id": "a7ab4db130bd018b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model.eval()\n",
    "\n",
    "df = pd.read_csv(\"package/test.csv\")\n",
    "\n",
    "pred_list = []\n",
    "for row in df[\"file\"]:\n",
    "    img_path = f\"package/renders/{row}\"\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    img_tensor = transform(img).unsqueeze(0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        predict = model(img_tensor.to(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "        print([row, round(predict[0][0].item(),3) , round(predict[0][1].item(), 3), round(predict[0][2].item(), 3), round(predict[0][3].item(), 3)])\n",
    "    pred_list.append([row, round(predict[0][0].item(),3) , round(predict[0][1].item(), 3), round(predict[0][2].item(), 3), round(predict[0][3].item(), 3)])\n",
    "\n",
    "pred_df = pd.DataFrame(pred_list, columns=[\"file\", \"posx\", \"posy\", \"rotx\", \"roty\"])\n",
    "pred_df.to_csv(\"package/test.csv\", index=False)\n"
   ],
   "id": "d2448231391a79b6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "This yields and accuracy of **89.3600%** which is the highest right now"
   ],
   "id": "20573cfc642d943f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
