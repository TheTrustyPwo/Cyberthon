{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Getting Hot"
      ],
      "metadata": {
        "collapsed": false,
        "id": "46LAcbbbBbYF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem Statement\n",
        "\n",
        "In a world where information is power, the evil APOCALYPSE organization has harnessed the might of large language models (LLMs) to spread fake news and manipulate public opinion. These nefarious actors have weaponized cutting-edge AI technology to undermine trust in legitimate sources of information and sow discord among the population.\n",
        "\n",
        "But there is hope: a team of dedicated researchers and data scientists are working tirelessly to build a machine learning model that can detect LLM-generated content and flag it as potentially unreliable.\n",
        "\n",
        "This cutting-edge technology analyzes not only the content of the text, but also the temperature associated with it. LLM-generated text tends to have a distinct temperature signature, which the model can use to distinguish it from genuine human-generated content.\n",
        "\n",
        "You are given Base64 encoded sentences and their associated temperatures in train.csv but we are missing the temperatures for the Base64 encoded sentences in test.csv. Help us build a model to find the temperatures so we can stand up to the APOCALYPSE organization and their campaign of misinformation."
      ],
      "metadata": {
        "collapsed": false,
        "id": "hyqGSg2rBbYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Solution\n",
        "\n",
        "We are going to use tf-idf vectorizers to transform the text, then build a pytorch regression model and train it. Note that this dataset and model are quite intensive and hence were run on a more powerful server (RTX 4090 and 64GB Ram). However, there exists a much more computationally efficient solution that runs on Google Colab and obtains a close score to this model (Scroll down below)."
      ],
      "metadata": {
        "collapsed": false,
        "id": "J4qyxib1BbYG"
      }
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "!pip install transformers pandas numpy scikit-learn tensorflow nltk gputil"
      ],
      "metadata": {
        "scrolled": true,
        "id": "bDGf15NZBbYH"
      },
      "execution_count": null
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AObvIchjhWBO"
      },
      "outputs": [],
      "source": [
        "!tar -xf GettingHot.tar.xz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qTXKvz_aQhiH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import base64\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.stem.porter import PorterStemmer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HryNt8mGBbYH"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NJbEu5NoBbYH"
      },
      "outputs": [],
      "source": [
        "def process(text):\n",
        "  try: return base64.b64decode(text).decode()\n",
        "  except: return \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UKtJ4_WsBbYH"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"package/train.csv\")\n",
        "df['sentence'] = df['sentence'].map(process)\n",
        "\n",
        "# Split data into features and target\n",
        "X = df['sentence']\n",
        "y = df['temperature']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eXNh4KY7BbYI"
      },
      "outputs": [],
      "source": [
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "porter_stemmer = PorterStemmer()\n",
        "\n",
        "def text_process(text):\n",
        "    text_processed=tokenizer.tokenize(text)\n",
        "    text_processed = [porter_stemmer.stem(word) for word in text_processed]\n",
        "    return text_processed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tkysJCmgBbYI"
      },
      "outputs": [],
      "source": [
        "char_vec = TfidfVectorizer(analyzer='char', ngram_range=(3, 3), max_features=5000).fit(X)\n",
        "word_vec = TfidfVectorizer(analyzer='word', ngram_range=(1, 1), tokenizer=text_process, max_features=5000).fit(X)\n",
        "bigram_vec = TfidfVectorizer(analyzer='word', ngram_range=(2, 2), tokenizer=text_process, max_features=2500).fit(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_1UxJH7BbYI"
      },
      "outputs": [],
      "source": [
        "# Define custom vectorizer with multiple transformers\n",
        "class CustomVectorizer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomVectorizer, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        char_features = torch.tensor(char_vec.transform(x).toarray(), dtype=torch.float32)\n",
        "        word_features = torch.tensor(word_vec.transform(x).toarray(), dtype=torch.float32)\n",
        "        bigram_features = torch.tensor(bigram_vec.transform(x).toarray(), dtype=torch.float32)\n",
        "        return torch.cat((char_features, word_features, bigram_features), dim=1)\n",
        "\n",
        "# Tokenize text\n",
        "vectorizer = CustomVectorizer()\n",
        "X = vectorizer(X)\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "y = torch.tensor(y.values, dtype=torch.float32)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O8EnGXs1BbYI"
      },
      "outputs": [],
      "source": [
        "# Define the model architecture\n",
        "class RegressionModel(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(RegressionModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 2048)\n",
        "        self.fc2 = nn.Linear(2048, 128)\n",
        "        self.fc3 = nn.Linear(128, 1)\n",
        "        self.dropout = nn.Dropout(p=0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Initialize the model\n",
        "input_dim = X_train.shape[1]\n",
        "model = RegressionModel(input_dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OoZcD49hBbYI"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qd0fzb-QBbYI"
      },
      "outputs": [],
      "source": [
        "# Define loss function and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Define DataLoader\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Train the model\n",
        "model.train()\n",
        "for epoch in range(10):\n",
        "    running_loss = 0.0\n",
        "    with tqdm(total=len(train_loader), desc=f'Epoch {epoch+1}/10', unit='batch') as pbar:\n",
        "        for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels.unsqueeze(1))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            pbar.set_postfix({'loss': running_loss / ((batch_idx + 1) * train_loader.batch_size)})\n",
        "            pbar.update()\n",
        "\n",
        "# Evaluate the model\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    inputs, labels = X_test.to(device), y_test.to(device)\n",
        "    outputs = model(inputs)\n",
        "    mse = criterion(outputs, labels.unsqueeze(1)).item()\n",
        "    print(\"Mean Squared Error:\", mse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gRCRWTiGBbYI"
      },
      "outputs": [],
      "source": [
        "test_df = pd.read_csv(\"package/test.csv\")\n",
        "test_df['sentence'] = test_df['sentence'].map(process)\n",
        "test_X_torch = vectorizer(test_df['sentence'])\n",
        "test_dataset = TensorDataset(test_X_torch)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hIRD0WTOBbYI"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model on test data\n",
        "model.eval()\n",
        "outputs_array = []\n",
        "with torch.no_grad():\n",
        "    for inputs in tqdm(test_loader, desc=\"Testing\", unit=\"batch\"):\n",
        "        inputs = inputs[0].to(device)  # Extracting inputs from DataLoader\n",
        "        outputs = model(inputs)\n",
        "        outputs_array.extend(outputs.cpu().numpy().flatten())\n",
        "\n",
        "sub_df = pd.read_csv('package/submission.csv')\n",
        "sub_df['temperature'] = outputs_array\n",
        "sub_df.to_csv('package/submission.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This model obtains a score of **89**."
      ],
      "metadata": {
        "collapsed": false,
        "id": "NC152DYiBbYI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Solution (Using sklearn models\n",
        "\n",
        "The concept is similar to the above, more computationally expensive model, except it uses scipy's Ridge regression model."
      ],
      "metadata": {
        "collapsed": false,
        "id": "uDhKyv4vBbYI"
      }
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "pBi2SVreBbYI"
      },
      "execution_count": null
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import base64\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import FeatureUnion, Pipeline\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "metadata": {
        "id": "ygmMIIhsBbYI"
      },
      "execution_count": null
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "def process(text):\n",
        "  try: return base64.b64decode(text).decode()\n",
        "  except: return \"\""
      ],
      "metadata": {
        "id": "4dMvqfUjBbYJ"
      },
      "execution_count": null
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"package/train.csv\")\n",
        "df['processed'] = df['sentence'].map(process)\n",
        "df = df.dropna(subset=['processed'])\n",
        "\n",
        "# Split data into features and target\n",
        "X = df['processed']\n",
        "y = df['temperature']"
      ],
      "metadata": {
        "id": "2zJj4NXTBbYJ"
      },
      "execution_count": null
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "# Convert text data into TF-IDF features\n",
        "f_union = FeatureUnion(\n",
        "    transformer_list=[\n",
        "        ('char', Pipeline([\n",
        "            ('tfidf', TfidfVectorizer(analyzer='char', ngram_range=(3, 3), max_features=5000)),\n",
        "        ])),\n",
        "        ('text', Pipeline([\n",
        "            ('tfidf', TfidfVectorizer(analyzer='word', ngram_range=(1, 1), max_features=5000)),\n",
        "        ])),\n",
        "        ('word_bigrams', Pipeline([\n",
        "            ('tfidf', TfidfVectorizer(analyzer='word', ngram_range=(1, 2), max_features=2500)),\n",
        "        ])),\n",
        "    ],\n",
        ")\n",
        "\n",
        "model = Ridge(alpha=1.0)\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('union', f_union),\n",
        "    ('clf', model)\n",
        "])\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "B9yQd6zoBbYJ"
      },
      "execution_count": null
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test data\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Calculate mean squared error\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"Mean Squared Error:\", mse)"
      ],
      "metadata": {
        "id": "kGjNuCfwBbYJ"
      },
      "execution_count": null
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"package/test.csv\")\n",
        "df['processed'] = df['sentence'].map(process)\n",
        "X = df['processed']\n",
        "\n",
        "pred = pipeline.predict(X)\n",
        "df = pd.read_csv('package/submission.csv')\n",
        "df['temperature'] = pred\n",
        "df.to_csv('package/submission.csv', index=False)"
      ],
      "metadata": {
        "id": "J54siXUoBbYJ"
      },
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "This model yields a score of **~85**"
      ],
      "metadata": {
        "collapsed": false,
        "id": "5w4avS7nBbYJ"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}